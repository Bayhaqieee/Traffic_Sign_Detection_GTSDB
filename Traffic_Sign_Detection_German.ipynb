{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+TOe8u0nPk+HQDP/cbeo2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Traffic Sign Detection using GTSDB\n",
        "\n",
        "- Author    : Muhammad Aditya Bayhaqie\n",
        "- Practice  : Machine Learning Terapan (Dicoding)\n",
        "- Dataset   : [German Traffic Sign Detection Benchmark](https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/published-archive.html)"
      ],
      "metadata": {
        "id": "hgmPwuMi78O7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data and Library"
      ],
      "metadata": {
        "id": "3q72KHZL0hU0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COFQYn0Y2Dlf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, Dense, Flatten, Dropout, MaxPool2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.style.use('ggplot')\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4yf-pGA12vRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load the data\n",
        "training_file = \"/content/drive/MyDrive/Dataset/German_Traffic_Sign/train.p\"\n",
        "testing_file = \"/content/drive/MyDrive/Dataset/German_Traffic_Sign/test.p\"\n",
        "\n",
        "# Open and load the training file\n",
        "with open(training_file, mode='rb') as f:\n",
        "    train = pickle.load(f)\n",
        "\n",
        "# Open and load the testing file\n",
        "with open(testing_file, mode='rb') as f:\n",
        "    test = pickle.load(f)\n",
        "\n",
        "print(\"Data loaded\")"
      ],
      "metadata": {
        "id": "3KqY2ZSPaGB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "bEeI8ggg1cEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## File csv ini berupa ClassId dan SignName\n",
        "\n",
        "sign_name_df = pd.read_csv('/content/drive/MyDrive/Dataset/German Traffic Sign/signnames.csv')\n",
        "SIGN_NAMES = sign_name_df.SignName.values\n",
        "sign_name_df.set_index('ClassId', inplace=True)\n",
        "sign_name_df.head(10)"
      ],
      "metadata": {
        "id": "UX2Wbu4t1egJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Assignment"
      ],
      "metadata": {
        "id": "lx39r_f01jt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisikan fitur dan label untuk data training\n",
        "X, y = train['features'], train['labels']\n",
        "\n",
        "# Mengubah lists menjadi numpy arrays\n",
        "data = np.array(X)\n",
        "labels = np.array(y)\n",
        "print(data.shape, labels.shape)\n",
        "\n",
        "# Definisikan fitur dan label untuk data testing\n",
        "X_test, y_test = test['features'], test['labels']\n",
        "\n",
        "# Mengubah lists menjadi numpy arrays\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "gLYVH82T1hpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Split"
      ],
      "metadata": {
        "id": "U2tU8dZx1_-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split training data into train and val\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
      ],
      "metadata": {
        "id": "VsXijHUs2A9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kita visualisasikan datanya"
      ],
      "metadata": {
        "id": "JWEnUA5N2xmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_labels = np.unique(y_train).size\n",
        "def hist_data(y_data, title=None, ax=None, **kwargs):\n",
        "    if not ax :\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111)\n",
        "    ax.hist(y_data, np.arange(-0.5, n_labels+1.5), stacked=True, **kwargs)\n",
        "    ax.set_xlim(-0.5, n_labels-0.5)\n",
        "    if 'label' in kwargs : ax.legend()\n",
        "    if title : ax.set_title(title)\n",
        "\n",
        "fig,ax = plt.subplots(1,3, figsize=(20,5))\n",
        "hist_data(y_train, title='Distribusi kelas pada data training', ax=ax[0])\n",
        "hist_data(y_val, title='Distribusi kelas pada data validasi', ax=ax[1], color='black')\n",
        "hist_data(y_test, title='Distribusi kelas pada data test', ax=ax[2], color='grey')"
      ],
      "metadata": {
        "id": "cZxjVJsU2yIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "SxYIBBxX3FAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Encoding"
      ],
      "metadata": {
        "id": "XvXVd8xM3G-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Konversi label dengan teknik one hot encoding\n",
        "y_train = to_categorical(y_train, 43)\n",
        "y_val = to_categorical(y_val, 43)"
      ],
      "metadata": {
        "id": "p_baa6v520OV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "SQzHfJF443Nj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sebelum training, mari kita set dulu callback!"
      ],
      "metadata": {
        "id": "Gx2KPOO65Hva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') > 0.96):\n",
        "      print(\"\\nAkurasi telah mencapai >96%. Stop training!\")\n",
        "      self.model.stop_training = True\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "j66HtcKt46d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, mari kita buat Lapisan pertama untuk CNN kita! dalam hal ini detailnya ialah\n",
        "\n",
        "- Ukuran filter untuk proses konvolusi=32\n",
        "- Ukuran kernel=(5,5)\n",
        "- Fungsi aktivasi RELU\n",
        "- Pooling yang kita gunakan adalah Maxpool dengan ukuran 2,2\n",
        "- Dropout rate sebesar 0.25"
      ],
      "metadata": {
        "id": "VmtSCCSJ6gkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
        "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25))"
      ],
      "metadata": {
        "id": "VdO20dDc6gPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya, mari kita buat lapisan kedua!"
      ],
      "metadata": {
        "id": "4ABhgoWs6ytt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))"
      ],
      "metadata": {
        "id": "F6FKkSWH60Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next up, mari kita selesaikan dengan menggunakan FCL!"
      ],
      "metadata": {
        "id": "qA5i5g9m64EE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(43, activation='softmax'))"
      ],
      "metadata": {
        "id": "CbYuKxoI7CA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sebagai tambahan, kita akan menerapkan penggunaan pada Dense Layer!\n",
        "\n",
        "Dense layer merupakan lapisan saraf yang menerima input dari semua neuron pada lapisan sebelumnya."
      ],
      "metadata": {
        "id": "H4fKlXRH7H-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(43, activation='softmax'))"
      ],
      "metadata": {
        "id": "KLD8Vfx47N5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mari kita lihat arsitektur dari model yang telah kita buat!"
      ],
      "metadata": {
        "id": "qc0dBhCJ7S7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "wFj16myv7UsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next up, let's Compile the model!"
      ],
      "metadata": {
        "id": "e4_1Gn8c7gR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "epochs = 25\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_val, y_val), callbacks=[callbacks])\n",
        "model.save(\"my_model.h5\")"
      ],
      "metadata": {
        "id": "WKaY8AOz7flY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah dirun, mari kita visualisasikan modelnya!"
      ],
      "metadata": {
        "id": "p5Hos33m7q78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting graphs for accuracy\n",
        "plt.figure(0)\n",
        "plt.plot(history.history['accuracy'], label='training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting graphs for loss\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gdBKodBW7tfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Model"
      ],
      "metadata": {
        "id": "2l_1cXOU71Ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred=np.argmax(model.predict(X_test), axis=-1)\n",
        "accuracy_score(y_test, pred)"
      ],
      "metadata": {
        "id": "jasLzPKM72cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "4YrcX-oZ9d5r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}